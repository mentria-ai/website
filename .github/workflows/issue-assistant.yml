name: Issue Assistant

on:
  issues:
    types: [opened, edited]
  issue_comment:
    types: [created, edited]

# Adding explicit permission scoping for security
permissions:
  contents: read
  issues: write
  actions: read

jobs:
  respond-to-issue:
    runs-on: self-hosted
    
    steps:
      - name: Validate API key
        run: |
          echo "Validating Together API key..."
          if [[ -z "${{ secrets.TOGETHER_API_KEY }}" ]]; then
            echo "::error::Missing Together API key. Please add it to your repository secrets."
            exit 1
          fi
          
          # Validate format without revealing content
          if [[ ! "${{ secrets.TOGETHER_API_KEY }}" =~ ^[A-Za-z0-9+/=_-]+$ ]]; then
            echo "::warning::API key has unexpected format, may cause issues"
          else
            echo "API key format validation passed"
          fi
      
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Initialize workflow
        id: init
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            
            // Load logging utilities
            const loggerPath = './.github/shared/utils/logging.js';
            if (!fs.existsSync(loggerPath)) {
              return core.setFailed('Logging utilities not found');
            }
            
            const logger = require(`${process.env.GITHUB_WORKSPACE}/${loggerPath}`);
            const logFile = logger.initLogFile('Issue Assistant', context);
            
            // Start logging
            logger.logSection(logFile, "Workflow Initialization");
            logger.logMessage(logFile, "- Event: " + context.eventName);
            logger.logMessage(logFile, "- Action: " + context.payload.action);
            logger.logMessage(logFile, "- Actor: " + context.actor);
            
            // Make log file available to all steps
            core.setOutput('log_file', logFile);
            
            // Basic validation
            if (context.eventName !== 'issues' && context.eventName !== 'issue_comment') {
              logger.logError(logFile, `Unsupported event type: ${context.eventName}`);
              return core.setFailed(`Unsupported event type: ${context.eventName}`);
            }
            
            // Validate event payload
            if (context.eventName === 'issues' && !context.payload.issue) {
              logger.logError(logFile, 'Missing issue data in event payload');
              return core.setFailed('Missing issue data in event payload');
            }
            
            if (context.eventName === 'issue_comment') {
              if (!context.payload.issue) {
                logger.logError(logFile, 'Missing issue data in comment event payload');
                return core.setFailed('Missing issue data in comment event payload');
              }
              
              if (!context.payload.comment) {
                logger.logError(logFile, 'Missing comment data in event payload');
                return core.setFailed('Missing comment data in event payload');
              }
            }
            
            logger.logSuccess(logFile, 'Input validation passed');
            return { log_file: logFile };
      
      - name: Extract issue content
        id: get-content
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const logFile = '${{ steps.init.outputs.log_file }}';
            
            // Load utilities
            const loggerPath = './.github/shared/utils/logging.js';
            const eventExtractorPath = './.github/shared/event-handlers/event-extractor.js';
            
            if (!fs.existsSync(loggerPath) || !fs.existsSync(eventExtractorPath)) {
              return core.setFailed('Required modules not found');
            }
            
            const logger = require(`${process.env.GITHUB_WORKSPACE}/${loggerPath}`);
            const eventExtractor = require(`${process.env.GITHUB_WORKSPACE}/${eventExtractorPath}`);
            
            logger.logSection(logFile, "Content Extraction");
            
            try {
              // Extract content from issue or comment
              const contentResult = eventExtractor.extractIssueContent(context.payload, logFile, logger);
              
              if (!contentResult.success) {
                logger.logError(logFile, `Failed to extract content: ${contentResult.error}`);
                return core.setFailed(`Failed to extract content: ${contentResult.error}`);
              }
              
              // Get previous comments for context
              let previousComments = [];
              
              if (context.eventName === 'issue_comment' || context.payload.action === 'edited') {
                try {
                  logger.logMessage(logFile, "Fetching previous comments for context");
                  
                  // Use REST API to fetch issue comments
                  const { data: comments } = await github.rest.issues.listComments({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: contentResult.issueNumber,
                    per_page: 10
                  });
                  
                  // Format comments for context
                  previousComments = comments.map(comment => ({
                    author: comment.user.login,
                    body: comment.body,
                    createdAt: comment.created_at
                  }));
                  
                  logger.logSuccess(logFile, `Retrieved ${previousComments.length} previous comments`);
                } catch (error) {
                  logger.logWarning(logFile, `Error retrieving previous comments: ${error.message}`);
                  // Continue without previous comments - non-critical error
                }
              }
              
              // Create a JSON file with all extracted content for the next step
              const extractedData = {
                ...contentResult,
                previousComments
              };
              
              fs.writeFileSync('content_data.json', JSON.stringify(extractedData, null, 2));
              
              logger.logSuccess(logFile, "Content extraction completed successfully");
              
              return {
                issue_id: contentResult.issueId,
                issue_number: contentResult.issueNumber,
                comment_id: contentResult.commentId,
                content_file: contentResult.contentFile,
                base64_file: contentResult.base64File
              };
            } catch (error) {
              logger.logError(logFile, `Error in content extraction: ${error.message}`);
              return core.setFailed(`Error in content extraction: ${error.message}`);
            }
      
      - name: Analyze repository context needs
        id: check-context
        run: |
          echo "Starting repository context analysis..." >> ${{ steps.init.outputs.log_file }}
          
          # Create directories for analysis
          mkdir -p context_analysis error_logs
          
          # Check if content data exists
          if [ ! -f "content_data.json" ]; then
            echo "❌ Error: content_data.json file not found" >> ${{ steps.init.outputs.log_file }}
            echo "needs_context=false" >> $GITHUB_OUTPUT
            echo "reason=Failed to analyze context needs - missing content data" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Extract content to a temporary file to avoid shell expansion issues
          jq -r '.content' content_data.json > context_analysis/content.txt
          
          # Create the request JSON using jq to properly handle escaping
          jq -n --rawfile content context_analysis/content.txt '{
            model: "deepseek-ai/DeepSeek-R1",
            messages: [
              {
                role: "user",
                content: "You are a tool that analyzes GitHub issue or discussion messages to determine if repository context would be helpful to answer the query. Respond with only a JSON object containing two fields: \"needsContext\" (boolean) and \"reason\" (string).\n\nAnalyze this GitHub issue/discussion text and determine if repository code context would be helpful to answer it properly:\n\n" + $content + "\n\nRespond with JSON only, format: {\"needsContext\": boolean, \"reason\": \"your explanation\"}"
              }
            ]
          }' > context_analysis/request.json
          
          # Make sure the request file was created properly
          if [ ! -s "context_analysis/request.json" ]; then
            # Fallback approach
            cat > context_analysis/request.json << EOL
          {
            "model": "deepseek-ai/DeepSeek-R1",
            "messages": [
              {
                "role": "user",
                "content": "You are a tool that analyzes GitHub issue or discussion messages to determine if repository context would be helpful to answer the query. Respond with only a JSON object containing two fields: \"needsContext\" (boolean) and \"reason\" (string).\n\nAnalyze this GitHub issue/discussion text and determine if repository code context would be helpful to answer it properly:\n\n$(cat context_analysis/content.txt)\n\nRespond with JSON only, format: {\"needsContext\": boolean, \"reason\": \"your explanation\"}"
              }
            ]
          }
          EOL
            echo "Used fallback method for request JSON creation" >> ${{ steps.init.outputs.log_file }}
          fi
          
          # Call the API
          curl -s -X POST "https://api.together.xyz/v1/chat/completions" \
            -H "Authorization: Bearer ${{ secrets.TOGETHER_API_KEY }}" \
            -H "Content-Type: application/json" \
            -d @context_analysis/request.json \
            -o context_analysis/response.json
          
          # Check if the response file exists and has content
          if [ -s "context_analysis/response.json" ]; then
            # Extract the response content to a file
            jq -r '.choices[0].message.content' context_analysis/response.json > context_analysis/ai_response.txt
            
            # Extract JSON using grep
            grep -o '{.*}' context_analysis/ai_response.txt > context_analysis/json_extract.txt || echo "{}" > context_analysis/json_extract.txt
            
            # Default values
            NEEDS_CONTEXT="false"
            REASON="Failed to analyze context needs"
            
            # Try to extract values from the JSON if file exists and has content
            if [ -s "context_analysis/json_extract.txt" ]; then
              EXTRACTED_NEEDS_CONTEXT=$(jq -r '.needsContext // false' context_analysis/json_extract.txt)
              EXTRACTED_REASON=$(jq -r '.reason // "No reason provided"' context_analysis/json_extract.txt)
              
              if [ "$EXTRACTED_NEEDS_CONTEXT" == "true" ]; then
                NEEDS_CONTEXT="true"
              fi
              
              if [ ! -z "$EXTRACTED_REASON" ] && [ "$EXTRACTED_REASON" != "null" ]; then
                REASON="$EXTRACTED_REASON"
              fi
            fi
            
            echo "Context analysis result: $NEEDS_CONTEXT" >> ${{ steps.init.outputs.log_file }}
            echo "Reason: $REASON" >> ${{ steps.init.outputs.log_file }}
            
            # Set outputs
            echo "needs_context=$NEEDS_CONTEXT" >> $GITHUB_OUTPUT
            echo "reason=$REASON" >> $GITHUB_OUTPUT
          else
            echo "❌ Error: No response from API or empty response" >> ${{ steps.init.outputs.log_file }}
            # Default to not needing context
            echo "needs_context=false" >> $GITHUB_OUTPUT
            echo "reason=Failed to analyze context needs" >> $GITHUB_OUTPUT
          fi
      
      - name: Get repository context
        id: get-repo-context
        if: steps.check-context.outputs.needs_context == 'true'
        run: |
          echo "Getting repository context..." >> ${{ steps.init.outputs.log_file }}
          
          # Load content data
          CONTENT=$(cat content_data.json | jq -r '.content')
          
          # We'll use a simpler approach for repo context in the shell script
          # Just identify some relevant files based on keywords in the content
          
          # Extract keywords from content
          KEYWORDS=$(echo "$CONTENT" | tr -cs '[:alnum:]' '\n' | sort | uniq | grep -v '^$' | head -10)
          echo "Keywords extracted: $KEYWORDS" >> ${{ steps.init.outputs.log_file }}
          
          # Find relevant files (limited to 10)
          RELEVANT_FILES=""
          for keyword in $KEYWORDS; do
            if [ ${#keyword} -gt 3 ]; then  # Only use keywords longer than 3 chars
              FOUND_FILES=$(find . -type f -not -path "*/node_modules/*" -not -path "*/dist/*" -not -path "*/.git/*" -name "*${keyword}*" | head -3)
              RELEVANT_FILES="$RELEVANT_FILES $FOUND_FILES"
            fi
          done
          
          # Deduplicate files and limit to 10
          RELEVANT_FILES=$(echo "$RELEVANT_FILES" | tr ' ' '\n' | sort | uniq | grep -v '^$' | head -10)
          
          # Format the repository context
          echo -e "## Repository Context\n\n" > repo_context.md
          echo -e "### Repository Structure\n" >> repo_context.md
          find . -maxdepth 2 -type d | sort | head -10 | sed 's/^/- /' >> repo_context.md
          echo -e "\n\n### Relevant Files\n\n" >> repo_context.md
          
          # Read file contents and add to context
          FILE_COUNT=0
          for file in $RELEVANT_FILES; do
            if [ -f "$file" ]; then
              EXTENSION="${file##*.}"
              echo -e "#### ${file}\n\`\`\`${EXTENSION}" >> repo_context.md
              head -50 "$file" >> repo_context.md
              echo -e "\n\`\`\`\n\n" >> repo_context.md
              FILE_COUNT=$((FILE_COUNT+1))
            fi
          done
          
          echo "Repository context extracted with ${FILE_COUNT} files" >> ${{ steps.init.outputs.log_file }}
          
          # Set output
          echo "context_file=repo_context.md" >> $GITHUB_OUTPUT
          echo "file_count=${FILE_COUNT}" >> $GITHUB_OUTPUT
      
      - name: Generate AI response
        id: generate-response
        run: |
          echo "Generating AI response..." >> ${{ steps.init.outputs.log_file }}
          
          # Create response directory
          mkdir -p response_files
          
          # Load content data
          CONTENT_DATA=$(cat content_data.json)
          CONTENT=$(echo "$CONTENT_DATA" | jq -r '.content')
          EVENT_TYPE=$(echo "$CONTENT_DATA" | jq -r '.eventType')
          
          # Load repository context if available
          REPO_CONTEXT=""
          if [[ "${{ steps.check-context.outputs.needs_context }}" == "true" ]] && [[ -f "repo_context.md" ]]; then
            REPO_CONTEXT=$(cat repo_context.md)
            echo "Loaded repository context ($(wc -c < repo_context.md) bytes)" >> ${{ steps.init.outputs.log_file }}
          fi
          
          # Combine system and user prompts into a single user prompt
          cat > response_files/combined_prompt.txt << 'EOF'
          You are an AI assistant that helps with GitHub issues. You provide helpful, accurate, and concise responses to technical questions and issues.

          When responding, follow these guidelines:
          1. Be direct and get straight to the point
          2. Use markdown formatting to structure your responses
          3. When code is needed, use proper syntax highlighting with markdown code blocks (e.g., ```javascript)
          4. If you're uncertain, acknowledge limitations rather than making things up
          5. You may include your reasoning process in <think></think> tags - this will be formatted as a quote block in the final response
          6. For complex technical questions, break down your approach step by step
          7. If you reference specific parts of code files, cite the file path and line numbers
          8. Keep your responses focused on the technical issue at hand

          Remember that you're responding in a GitHub issue context. Your goal is to be helpful, accurate, and drive toward issue resolution.

          Please respond to this 
          EOF
          
          # Append event type and content
          echo "${EVENT_TYPE}:" >> response_files/combined_prompt.txt
          echo "" >> response_files/combined_prompt.txt
          echo "$CONTENT" >> response_files/combined_prompt.txt
          
          # Add context if available
          if [[ ! -z "$REPO_CONTEXT" ]]; then
            echo "" >> response_files/combined_prompt.txt
            echo "$REPO_CONTEXT" >> response_files/combined_prompt.txt
          fi
          
          # Create request payload using jq to properly escape JSON
          jq -n \
            --arg prompt "$(cat response_files/combined_prompt.txt)" \
            '{
              "model": "deepseek-ai/DeepSeek-R1",
              "messages": [
                {
                  "role": "user",
                  "content": $prompt
                }
              ]
            }' > response_files/payload.json
          
          # Make API call
          curl -s -X POST "https://api.together.xyz/v1/chat/completions" \
            -H "Authorization: Bearer ${{ secrets.TOGETHER_API_KEY }}" \
            -H "Content-Type: application/json" \
            -d @response_files/payload.json \
            -o response_files/api_response.json
          
          # Check response and extract content
          if [ -s "response_files/api_response.json" ]; then
            # Extract content
            CONTENT=$(cat response_files/api_response.json | jq -r '.choices[0].message.content')
            
            # Process <think> blocks with a separate script
            cat > process_thinking.awk << 'EOF'
            BEGIN { in_think = 0; output = ""; thinking = ""; }
            
            # Start of thinking block
            /<think>/ { 
              in_think = 1; 
              thinking = ""; 
              next; 
            }
            
            # End of thinking block
            /<\/think>/ { 
              in_think = 0;
              # If there was thinking content, format it as markdown quote
              if (thinking != "") {
                # Split thinking into lines and prefix each with >
                split(thinking, lines, "\n");
                output = output "\n\n> **Thinking process:**\n";
                for (i in lines) {
                  if (lines[i] != "") {
                    output = output "> " lines[i] "\n";
                  } else {
                    output = output ">\n";
                  }
                }
                output = output "\n";
              }
              next;
            }
            
            # Inside thinking block - collect content
            in_think == 1 { 
              thinking = thinking (thinking=="" ? "" : "\n") $0;
              next;
            }
            
            # Normal content outside thinking blocks
            in_think == 0 { 
              output = output (output=="" ? "" : "\n") $0;
            }
            
            END { print output; }
            EOF
            
            # Run the awk script to process thinking blocks
            processed_content=$(awk -f process_thinking.awk <<< "$CONTENT")
            
            # Save processed content
            echo "$processed_content" > response.txt
            echo "Generated AI response successfully ($(wc -c < response.txt) bytes)" >> ${{ steps.init.outputs.log_file }}
            
            # Set output
            echo "response_file=response.txt" >> $GITHUB_OUTPUT
            echo "content_length=$(wc -c < response.txt)" >> $GITHUB_OUTPUT
          else
            echo "❌ Error: API request failed or returned empty response" >> ${{ steps.init.outputs.log_file }}
            echo "I apologize, but I'm currently experiencing technical difficulties. Please try again later." > response.txt
            echo "response_file=response.txt" >> $GITHUB_OUTPUT
          fi
      
      - name: Post response to issue
        id: post-response
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const logFile = '${{ steps.init.outputs.log_file }}';
            
            // Load utilities
            const loggerPath = './.github/shared/utils/logging.js';
            const responseHandlerPath = './.github/shared/response-handlers/github-response.js';
            
            if (!fs.existsSync(loggerPath) || !fs.existsSync(responseHandlerPath)) {
              return core.setFailed('Required modules not found');
            }
            
            const logger = require(`${process.env.GITHUB_WORKSPACE}/${loggerPath}`);
            const responseHandler = require(`${process.env.GITHUB_WORKSPACE}/${responseHandlerPath}`);
            
            logger.logSection(logFile, "Posting Response");
            
            try {
              // Get response content
              const responseFile = 'response.txt';
              if (!fs.existsSync(responseFile)) {
                logger.logError(logFile, "Response file not found");
                return core.setFailed("Response file not found");
              }
              
              const responseContent = fs.readFileSync(responseFile, 'utf8');
              logger.logMessage(logFile, `Loaded response content (${responseContent.length} bytes)`);
              
              // Load issue number
              const issueNumber = parseInt('${{ steps.get-content.outputs.issue_number }}', 10);
              
              if (!issueNumber || isNaN(issueNumber)) {
                logger.logError(logFile, "Missing or invalid issue number");
                return core.setFailed("Missing or invalid issue number");
              }
              
              // Post to issue
              const postResult = await responseHandler.postToIssue({
                github,
                issueNumber,
                responseContent,
                logFile,
                logger,
                context
              });
              
              if (!postResult.success) {
                logger.logError(logFile, `Failed to post response: ${postResult.error}`);
                return core.setFailed(`Failed to post response: ${postResult.error}`);
              }
              
              logger.logSuccess(logFile, `Successfully posted response with ID: ${postResult.commentId}`);
              
              return {
                comment_id: postResult.commentId,
                success: true
              };
            } catch (error) {
              logger.logError(logFile, `Error posting response: ${error.message}`);
              return core.setFailed(`Error posting response: ${error.message}`);
            }
      
      - name: Finalize workflow
        if: always()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            
            try {
              const logFile = '${{ steps.init.outputs.log_file }}';
              if (!logFile || !fs.existsSync(logFile)) {
                console.log('Log file not found or not specified');
                return;
              }
              
              const loggerPath = './.github/shared/utils/logging.js';
              if (!fs.existsSync(loggerPath)) {
                console.log('Logger module not found');
                return;
              }
              
              const logger = require(`${process.env.GITHUB_WORKSPACE}/${loggerPath}`);
              
              // Create summary of outcomes
              const outcomes = {
                result: '${{ steps.post-response.outcome }}' === 'success' ? 'success' : 'failure',
                eventType: context.eventName,
                action: context.payload.action || 'N/A',
                repoContextUsed: '${{ steps.check-context.outputs.needs_context }}' === 'true'
              };
              
              logger.finalizeLog(logFile, context, outcomes);
              console.log(`Workflow log finalized at ${logFile}`);
            } catch (error) {
              console.error(`Error finalizing workflow: ${error.message}`);
            }
      
      - name: Upload workflow logs as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: workflow-logs
          path: |
            workflow_*.log
            content_files/
            context_analysis/
            response_files/
          retention-days: 5 